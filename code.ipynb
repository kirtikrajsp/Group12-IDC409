{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVzY0ASO/J844bIjIEJT8r"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mX_ZmWzV2y1y"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import re\n",
        "import numpy as np\n",
        "import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import curve_fit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fetching main faculty page...\")\n",
        "data = requests.get('https://www.iiserkol.ac.in/web/en/people/faculty/dbs/')\n",
        "soup = BeautifulSoup(data.content, \"html.parser\")\n",
        "\n",
        "# Collecting faculty profile URLs\n",
        "urls = [link['href'] for link in soup.find_all('a')]\n",
        "urls = [url for url in urls if '/web/en/people/faculty/dbs/' in url]\n",
        "link = 'https://www.iiserkol.ac.in'\n",
        "faculty_websites = list(set([link + url for url in urls]))\n",
        "print(f\"Found {len(faculty_websites)} faculty profile URLs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIBr8HO94oRM",
        "outputId": "e2f35e5e-f460-4091-b957-00afbea90de8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching main faculty page...\n",
            "Found 27 faculty profile URLs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "print(\"Scraping individual faculty pages...\")\n",
        "\n",
        "for faculty_url in faculty_websites:\n",
        "    try:\n",
        "        data = requests.get(faculty_url)\n",
        "        data.raise_for_status()\n",
        "        soup = BeautifulSoup(data.content, \"html.parser\")\n",
        "\n",
        "        # Get faculty name\n",
        "        name = soup.find_all('h3')\n",
        "        faculty_name = [name.text for name in name]\n",
        "        faculty_name = faculty_name[3].strip() if len(faculty_name) > 3 else None\n",
        "\n",
        "        if not faculty_name:\n",
        "            print(f\"Skipping URL (could not find name): {faculty_url}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing: {faculty_name}\")\n",
        "\n",
        "        # Initialize profile dictionary\n",
        "        profile_data = {\n",
        "            \"Name\": faculty_name,\n",
        "            \"Positions\": None,\n",
        "            \"Academic Background\": None,\n",
        "            \"PhD\": None,\n",
        "            \"PhD Year\": None,\n",
        "            \"Research Interest\": None,\n",
        "            \"Awards and Honors\": None,\n",
        "            \"Number of awards\": None,\n",
        "        }\n",
        "\n",
        "        # Get main profile content\n",
        "        content = soup.find_all('div', class_='col-md-12 innerdiv')\n",
        "\n",
        "        for section in content:\n",
        "            section_text = section.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "            if 'Positions:' in section_text:\n",
        "                profile_data[\"Positions\"] = re.sub(r'Positions:\\s+', '', section_text)\n",
        "\n",
        "            elif 'Academic Background:' in section_text:\n",
        "                profile_data[\"Academic Background\"] = re.sub(r'Academic Background:\\s+', '', section_text)\n",
        "\n",
        "                # Try to extract PhD info from this section\n",
        "                c = re.search(r\"\\d{4}\", section_text) # Look for a 4-digit year\n",
        "                if c:\n",
        "                    x = c.start()\n",
        "                    profile_data[\"PhD Year\"] = section_text[x:x+4]\n",
        "                    if 'PhD' in section_text or 'phd' in section_text or 'Ph.D' in section_text:\n",
        "                        phd_text = section_text[21:x-1].strip(\" ,\")\n",
        "                        profile_data[\"PhD\"] = phd_text\n",
        "\n",
        "            elif 'Research Interest:' in section_text:\n",
        "                profile_data[\"Research Interest\"] = re.sub(r'Research Interest:\\s+', '', section_text)\n",
        "\n",
        "\n",
        "            elif 'Awards and Honors:' in section_text:\n",
        "                profile_data[\"Awards and Honors\"] = re.sub(r'Awards and Honors:\\s+', '', section_text)\n",
        "                try:\n",
        "                    award_count = (section_text.count('20') + section_text.count('19') -\n",
        "                                   section_text.count('2020') - section_text.count('2019'))\n",
        "                    profile_data[\"Number of awards\"] = award_count\n",
        "                except Exception:\n",
        "                    profile_data[\"Number of awards\"] = None # No awards found\n",
        "\n",
        "\n",
        "        all_data.append(profile_data)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching URL {faculty_url}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(\"Scraping complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWkgtphLf1pf",
        "outputId": "a8efe4ef-4453-4f47-b444-a7c8b31a70b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping individual faculty pages...\n",
            "Processing: Partha Pratim Datta\n",
            "Processing: Anindita Bhadra\n",
            "Processing: Supratim Datta\n",
            "Processing: Sunil Kumar Khare\n",
            "Processing: Punyasloke Bhadury\n",
            "Processing: Sreeramaiah Gangappa\n",
            "Processing: Sumit Sen Santara\n",
            "Processing: Arnab Gupta\n",
            "Processing: Radhika Venkatesan\n",
            "Processing: Annagiri Sumana\n",
            "Processing: Bidisha Sinha\n",
            "Processing: Robert John Chandran\n",
            "Processing: Partho Sarothi Ray\n",
            "Processing: Tapas Kumar Sengupta\n",
            "Processing: Neelanjana Sengupta\n",
            "Processing: Amit Kumar Mandal\n",
            "Processing: Mohit Prasad\n",
            "Processing: Dipjyoti Das\n",
            "Processing: Malancha Ta\n",
            "Processing: Babu Sudhamalla\n",
            "Processing: Rupak Datta\n",
            "Processing: Jayasri Das Sarma\n",
            "Processing: Anuradha Bhat\n",
            "Processing: Rituparna Sinha Roy\n",
            "Processing: Rahul Das\n",
            "Processing: Sankar Maiti\n",
            "Processing: Amirul Islam Mallick\n",
            "Scraping complete.\n"
          ]
        }
      ]
    }
  ]
}